{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of LLM Agent against Ground Truth Labels for Spatial Clustering Methods\n",
    "## Introduction \n",
    "This research project seeks to answer the following question: \"Is it possible to create an agent that can understand and summarise the literature of spatial clustering methods employed in the field of spatial transcriptomics?\" I plan to answer this by creating my own LLM agent and comparing it against other existing LLM models. I improved the agent by employing RAG (Retrieval Augmented Generation) and specialised web search engine Tavily as tools for the Agent. Additional system prompts also were used to help guide the Agent for the nature of its responses. Evaluation of the agent was performed by comparing a large spreadsheet of various metrics and categories for each spatial clustering method generated from human experts against the results generated by the agent. Ablation for each tool has been performed to analyse further impacts of each tool added, and finally a comparison of the agent against the end-user application of ChatGPT was performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "The LLM Agent was developed using the Langchain framework, which allows for flexible abstractions during the development process. Langchain allows for easy integration of new features such as the use of embedding models for RAG and an AgentExecutor class for a useful interface for helping the agent choose a relevant tool when coming up with a response. \n",
    "\n",
    "### Model Selection\n",
    "Google Gemini Flash was chosen as it was free to use for a large number of tokens for educational purposes. \n",
    "\n",
    "### System Prompt\n",
    "The system was provided with a prompt that informs it that it is an assistant capable of answering various topics, from simple topics to deep discussions. It is also told to act as a spatial transcriptomics expert, and that answers should be kept technical, but concise. \n",
    "\n",
    "Additional system prompts include the definitions of various categories for each spatial algorithm as determined by human experts which can be seen [here](https://docs.google.com/spreadsheets/d/1P1-Nw0i_MpLoE8he1H7ZT-acYd4jOgDPrKZBxR-L6dw/edit?gid=0#gid=0). This ranged from things such as clustering method (Bayesian, Graph-based, Autoencoder, Centroid, Hierarchical-based), Scalability, Assumptions, Input data, programming language and metrics + simulations employed in the article. See the `prompts.py` file for more information regarding the specific details.\n",
    "\n",
    "### Information Review Sheet\n",
    "The spatial information review sheet had its categories filled in by 2 domain experts. On top of discrete categories, various columns of the sheet also contained details of the experts' thoughts of the algorithm on things such as realism, additional datasets, and comments.\n",
    "\n",
    "### RAG Process\n",
    "The RAG process begins by taking in a scientific article in the form of an input pdf file by loading it using the PyPDFLoader package. It is then broken down into several chunks using a RecursiveTextCharacterSplitter to improve proccessing efficiency, this can then be converted to vectors via an embedding model. The vectors are then stored in a Chroma vector database, which can be fetched from the LLM via a document retriever. A document retriever attempts to find the most relavant information in relation to a user query (In this case, the user's question). To improve the RAG process, an ensemble retriever was used consisting of the following: The first retriever uses a vector similarity search from the Chroma vector database by looking at vectors that were closer to the query in a high dimensional space. The second is a BM25 retriever which ranks the best match 25 chunks based on relevance to the given query.\n",
    "\n",
    "### Tavily Search\n",
    "Tavily Search API is a web search engine API that can be used by an LLM during the processing stage, it searches the web for additional relevant webpages by using the context of the user query. This helps fill in gaps and allows the Agent to infer certain details when the information of the article is insufficient for answering its questions. (I.e. Accessing the source code of the algorithm via public GitHub repository)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Method\n",
    "With all this in mind, let us discuss the details of the evaluation. Five different methods were evaluated:\n",
    "\n",
    "1. The Agent with all tools available.\n",
    "2. The Agent without Tavily Search.\n",
    "3. The Agent without document retrievers.\n",
    "4. The Agent with no tools available\n",
    "5. ChatGPT's end-user interface.\n",
    "\n",
    "In each of these methods, a scientific article of a spatial clustering method was provided, along with a user prommpt that tells the agent to categorise the spatial clustering method all the fields as described in the **System** Prompt section. With the following structure:\n",
    "\n",
    "<Category>,<Answer>\n",
    "\n",
    "Each result was stored in the form of a csv file under the file structure <method_name>/<article_name>.csv \n",
    "\n",
    "This process was repeated until all 5 methods contained all csvs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "With all this in mind, we can now begin the coding part.\n",
    "\n",
    "## Data Loading\n",
    "Dataframes were created by accessing each directory and reading each individual csv file. The csvs were transposed and added into a dataframe one row at a time. Once all csvs were retrieved and appended, an additional column specifying the LLM method was added to the dataframe.\n",
    "\n",
    "For the spatial clustering information sheet- the Google Sheets was directly read, specifying ranges with discrete values. And since currently the sheet is still under review, duplicate entries were removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def load_sheet(folder):\n",
    "    '''Given a folder, load all csv files for each clustering methods\n",
    "    folder: str of folder name\n",
    "    returns: A dataframe containing all LLM predictions for clustering categories'''\n",
    "    df = pd.read_csv(f\"{folder}/banksy.csv\", index_col= 0, skipinitialspace= True).transpose()\n",
    "    df.index = df.index.str.strip()\n",
    "\n",
    "    for sheet in os.listdir(folder)[1:]:\n",
    "        try: \n",
    "            if sheet.endswith(\".csv\"):\n",
    "                tmp_df = pd.read_csv(f\"{folder}/{sheet}\", index_col= 0, skipinitialspace= True).transpose()\n",
    "                tmp_df.index = tmp_df.index.str.strip()\n",
    "                df = pd.concat([df,tmp_df], axis = 0)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Error in {folder}\")\n",
    "            print(\"Adding in:\")\n",
    "            print(tmp_df)\n",
    "            print(\"Current\")\n",
    "            print(df)\n",
    "            break\n",
    "    \n",
    "\n",
    "    if df.columns[-1] == \"```\":\n",
    "        df = df.iloc[:,:-1]\n",
    "    df['Source'] = folder\n",
    "    return df\n",
    "\n",
    "def load_google_sheet():\n",
    "    '''Loads the spatial clustering review information sheet from google Sheets\n",
    "    returns: A dataframe containing all labels'''\n",
    "    gsheetid = \"1P1-Nw0i_MpLoE8he1H7ZT-acYd4jOgDPrKZBxR-L6dw\"\n",
    "    sheet_name = \"Methods\" \n",
    "    online_sheet = f\"https://docs.google.com/spreadsheets/d/{gsheetid}/gviz/tq?tqx=out:csv&sheet={sheet_name}&range=A2:A,I2:Y,AA2:AE,AH2:AW,AX2:BI,BL2:BQ,BS2:BU,BW2:CO,CQ2:CR,CT2:CX\"\n",
    "    info = pd.read_csv(online_sheet, index_col = 0)\n",
    "    info = info.dropna(subset = [\"Parameter testing\"])\n",
    "    info['Source'] = \"Truth\"\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = load_sheet(\"agent_out\")\n",
    "gpt = load_sheet(\"gpt_out\")\n",
    "pdfs = load_sheet(\"pdf_out\")\n",
    "search = load_sheet(\"search_out\")\n",
    "truth = load_google_sheet()\n",
    "truth = truth[~truth.index.duplicated(keep='first')]\n",
    "truth.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons \n",
    "To obtain the comparison between information sheet and agent output, column names were matched so that the dataframes could be joined, and filtered by method.\n",
    "\n",
    "Correctness of the agent was measured by counting the number of matching entries from the ground truth and agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Package</th>\n",
       "      <th>Bioconductor</th>\n",
       "      <th>CRAN</th>\n",
       "      <th>Vignette</th>\n",
       "      <th>Vignette with examples from different technologies</th>\n",
       "      <th>R</th>\n",
       "      <th>Python</th>\n",
       "      <th>C/C++</th>\n",
       "      <th>Centroid-based</th>\n",
       "      <th>...</th>\n",
       "      <th>Realistic</th>\n",
       "      <th>Unrealistic</th>\n",
       "      <th>Simulation included</th>\n",
       "      <th>Scalability assessment</th>\n",
       "      <th>Accuracy assessment</th>\n",
       "      <th>Stress testing</th>\n",
       "      <th>Parameter testing</th>\n",
       "      <th>Source</th>\n",
       "      <th>Correct_Terms</th>\n",
       "      <th>Correct_Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BASS</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>52</td>\n",
       "      <td>59.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DeepST</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>66</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GraphST</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>72.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEDR</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>72.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STAGATE</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>68.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SpaGCN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>63</td>\n",
       "      <td>71.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SpaceFlow</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>67</td>\n",
       "      <td>76.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SpatialPCA</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>65</td>\n",
       "      <td>73.863636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Algorithm  Package  Bioconductor  CRAN  Vignette  \\\n",
       "0        BASS     True          True  True      True   \n",
       "1      DeepST     True          True  True     False   \n",
       "2     GraphST     True          True  True     False   \n",
       "3        SEDR     True          True  True     False   \n",
       "4     STAGATE     True          True  True     False   \n",
       "5      SpaGCN     True          True  True     False   \n",
       "6   SpaceFlow     True          True  True     False   \n",
       "7  SpatialPCA     True          True  True     False   \n",
       "\n",
       "   Vignette with examples from different technologies     R  Python  C/C++  \\\n",
       "0                                              False   True    True   True   \n",
       "1                                               True   True    True   True   \n",
       "2                                               True   True    True   True   \n",
       "3                                              False   True    True   True   \n",
       "4                                               True   True    True   True   \n",
       "5                                              False   True    True   True   \n",
       "6                                              False   True    True   True   \n",
       "7                                               True   True    True   True   \n",
       "\n",
       "   Centroid-based  ...  Realistic  Unrealistic  Simulation included  \\\n",
       "0            True  ...       True        False                 True   \n",
       "1            True  ...       True         True                 True   \n",
       "2            True  ...       True         True                 True   \n",
       "3            True  ...       True         True                 True   \n",
       "4            True  ...       True         True                 True   \n",
       "5           False  ...       True         True                 True   \n",
       "6            True  ...       True         True                 True   \n",
       "7            True  ...       True         True                 True   \n",
       "\n",
       "   Scalability assessment  Accuracy assessment  Stress testing  \\\n",
       "0                   False                 True           False   \n",
       "1                   False                False            True   \n",
       "2                   False                False            True   \n",
       "3                    True                False            True   \n",
       "4                    True                False            True   \n",
       "5                   False                False            True   \n",
       "6                   False                False            True   \n",
       "7                   False                 True           False   \n",
       "\n",
       "   Parameter testing  Source  Correct_Terms  Correct_Percent  \n",
       "0              False   False             52        59.090909  \n",
       "1               True   False             66        75.000000  \n",
       "2              False   False             64        72.727273  \n",
       "3               True   False             64        72.727273  \n",
       "4              False   False             60        68.181818  \n",
       "5              False   False             63        71.590909  \n",
       "6               True   False             67        76.136364  \n",
       "7               True   False             65        73.863636  \n",
       "\n",
       "[8 rows x 89 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_df = pd.concat([agent, gpt, search, pdfs])\n",
    "llm_df.reset_index(inplace = True)\n",
    "llm_df.rename(columns = {\"index\":\"Algorithm\"}, inplace = True)\n",
    "llm_df.columns.name = None\n",
    "\n",
    "llm_df.columns = truth.columns\n",
    "\n",
    "def filter_and_compare(method):\n",
    "    '''Joins a method with a specified category and the ground truth dataframe together and \n",
    "    performs a comparison, by calculating the number of matching terms.\n",
    "    \n",
    "    method (str): Method to filter on \n",
    "    return: A dataframe containing the correctness of each algorithm'''\n",
    "    agent_filter = llm_df[llm_df['Source'] == method]\n",
    "\n",
    "    truth_filter = truth[truth['Algorithm'].isin(agent_filter['Algorithm'])]\n",
    "    agent_filter = agent_filter[agent_filter['Algorithm'].isin(truth['Algorithm'])]\n",
    "\n",
    "    agent_filter = agent_filter.sort_values(by= 'Algorithm').reset_index(drop = True)\n",
    "    truth_filter = truth_filter.sort_values(by= 'Algorithm').reset_index(drop = True)\n",
    "\n",
    "    compare = agent_filter.eq(truth_filter)\n",
    "    compare['Algorithm'] = agent_filter['Algorithm']\n",
    "    compare['Correct_Terms'] = compare.drop(columns='Algorithm').sum(axis = 1)\n",
    "    compare['Correct_Percent'] = 100* compare['Correct_Terms'] / compare.shape[1]\n",
    "    return compare\n",
    "\n",
    "filter_and_compare(\"agent_out\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
